{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Radiation Surfrad .dat Files to NetCDF4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the examples will be data from `Bondville_IL/`, and from the year 2016. Such files will be names `bon16###` where `###` denotes the julian day of the year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Radiation's Surfrad files have numerous headers:\n",
    "\n",
    "    YEAR DDD MM DD HH mm hh.mmm ZNAGL dw_psp qc uw_psp qc direct qc diffuse qc dw_pir qc dwCasTmp qc dwDomTmp qc uw_pir qc uwCastmp qc uwDomtmp qc uvb qc par qc netSolar qc netIr qc totalNet qc temp qc rh qc windSp qc winsDir qc Baro qc\n",
    "    \n",
    "All of those items, seperated by whitespace, are headers. An initial observation would show that the `qc` header shows up multiple times -- these are quality control flags for the preceding header. A `qc` value of 0 indicated values within an expected range, a value of 1 indicates a value outside of a physically possible range, a value of 2 indicates a value that is physically possible but \"should be used with scrutiny\". Missing values are indicated by a value of \"-9999.9\" and should always have a corresponding `qc` of \"1\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to .csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The .dat files are plain-text files delimited by whitespace. These files have no headers, only minimal site info and raw data. Here are the first several rows of the file `bon16001.dat`:\n",
    "\n",
    "     Bondville\n",
    "       40.05  -88.37  213 m version 1\n",
    "     2016   1  1  1  0  0  0.000 105.13    -3.4 0     0.0 0     0.8 0    -0.1 0   275.8 0   272.5 0   272.2 0   305.1 0   271.0 0   271.0 0     0.0 0     0.2 0     0.0 0   -29.3 0   -29.3 0    -2.2 0    76.5 0     6.8 0   270.0 0  1001.5 0\n",
    "     2016   1  1  1  0  1  0.017 105.32    -3.6 0     0.0 0     0.8 0    -0.1 0   267.7 0   272.5 0   272.1 0   304.4 0   271.0 0   271.0 0     0.0 0     0.2 0     0.0 0   -36.7 0   -36.7 0    -2.2 0    76.1 0     6.4 0   268.2 0  1001.5 0\n",
    "     2016   1  1  1  0  2  0.033 105.50    -3.6 0     0.0 0     0.7 0    -0.2 0   260.6 0   272.5 0   272.1 0   303.8 0   271.0 0   271.0 0     0.0 0     0.2 0     0.0 0   -43.1 0   -43.1 0    -2.2 0    77.3 0     6.0 0   272.1 0  1001.5 0\n",
    "     2016   1  1  1  0  3  0.050 105.68    -3.7 0     0.0 0     0.4 0    -0.1 0   252.5 0   272.5 0   272.1 0   303.1 0   270.9 0   270.9 0     0.0 0     0.2 0     0.0 0   -50.7 0   -50.7 0    -2.2 0    76.7 0     6.6 0   273.9 0  1001.5 0\n",
    "     2016   1  1  1  0  4  0.067 105.86    -3.8 0     0.0 0     0.4 0    -0.1 0   246.8 0   272.5 0   272.0 0   302.4 0   270.9 0   270.9 0     0.0 0     0.2 0     0.0 0   -55.6 0   -55.6 0    -2.2 0    77.0 0     6.0 0   278.4 0  1001.5 0\n",
    "\n",
    "Converting these files to .csv will essentially double the amount of storage needed for all the data. However, it seems to be a necessary step, due to the nature of the .dat files. The first step is to include the headers in the new .csv file. I've made a file called `headers.txt` (and a matching `headers.dat`) which contains all the headers that match up with Surfrad .dat files (and are delimited by whitespace). What follows can be found in the file `dat_to_csv.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from os.path import basename\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"YEAR\", \"DDD\", \"MM\", \"DD\", \"HH\", \"mm\", \"hh.mmm\", \"ZNAGL\", \"dw_psp\", \"qc\", \"uw_psp\", \"qc\", \"direct\", \"qc\", \"diffuse\", \"qc\", \"dw_pir\", \"qc\", \"dwCasTmp\", \"qc\", \"dwDomTmp\", \"qc\", \"uw_pir\", \"qc\", \"uwCastmp\", \"qc\", \"uwDomtmp\", \"qc\", \"uvb\", \"qc\", \"par\", \"qc\", \"netSolar\", \"qc\", \"netIr\", \"qc\", \"totalNet\", \"qc\", \"temp\", \"qc\", \"rh\", \"qc\", \"windSp\", \"qc\", \"winsDir\", \"qc\", \"Baro\", \"qc\"\n"
     ]
    }
   ],
   "source": [
    "with open(\"headers.dat\", 'r') as header_file:\n",
    "    for line in header_file:\n",
    "        headers = line.split() # this is an array of all the headers\n",
    "headers = ('\"%s\"') % '\", \"'.join(headers) # this formats the headers as a comma-delimited string\n",
    "\n",
    "print headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input = \"bon16001.dat\" # this is the file for this example, normally passed in via command line\n",
    "base = os.path.splitext(basename(input))[0] # this gets the name of the file (e.g \"bon16001.dat\" -> \"bon16001\")\n",
    "out_name = (base + \".csv\") # this is the name for the file to be written\n",
    "\n",
    "with open(input, 'r') as input_file:\n",
    "    with open(out_name, 'w') as output_file:\n",
    "        output_file.write(headers + \"\\n\") # this writes the headers to the new file\n",
    "        for count, line in enumerate(input_file):\n",
    "            if count < 2: # we can skip the first two lines of the input\n",
    "                pass\n",
    "            else:\n",
    "                if line.split()[0]=='\\x1a': # skip empty rows\n",
    "                    pass\n",
    "                else: # write the data delimited by commas\n",
    "                    outLine = \",\".join(line.split())\n",
    "                    output_file.write(outLine + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ther"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
